{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Nama : Mohammad Daffa Gashandy\n",
        "\n",
        "Kelas : KOMB\n",
        "\n",
        "NIM : 20/455449/PA/10664"
      ],
      "metadata": {
        "id": "Npe_RhWm-LhB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Implementasi ANN menggunakan library keras</b></h3>"
      ],
      "metadata": {
        "id": "EmMYG9AO-VG9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2f95UqC97Ln",
        "outputId": "e1a96110-d93e-4abc-9b31-295b51ab3146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train (108, 4)\n",
            "X_val (27, 4)\n",
            "X_test (15, 4)\n",
            "Epoch 1/64\n",
            "22/22 [==============================] - 1s 9ms/step - loss: 1.7310 - acc: 0.5833 - val_loss: 1.1230 - val_acc: 0.6667\n",
            "Epoch 2/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.9642 - acc: 0.6204 - val_loss: 0.7885 - val_acc: 0.7778\n",
            "Epoch 3/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.7728 - acc: 0.7037 - val_loss: 0.7065 - val_acc: 0.7407\n",
            "Epoch 4/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.7001 - acc: 0.7593 - val_loss: 0.6579 - val_acc: 0.8148\n",
            "Epoch 5/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6456 - acc: 0.8056 - val_loss: 0.6005 - val_acc: 0.7778\n",
            "Epoch 6/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.6162 - acc: 0.7593 - val_loss: 0.5602 - val_acc: 0.8519\n",
            "Epoch 7/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5798 - acc: 0.8056 - val_loss: 0.5336 - val_acc: 0.8519\n",
            "Epoch 8/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.5454 - acc: 0.8056 - val_loss: 0.5024 - val_acc: 0.8889\n",
            "Epoch 9/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5268 - acc: 0.8056 - val_loss: 0.4872 - val_acc: 0.8148\n",
            "Epoch 10/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.5225 - acc: 0.7222 - val_loss: 0.4706 - val_acc: 0.8148\n",
            "Epoch 11/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4885 - acc: 0.7778 - val_loss: 0.4481 - val_acc: 0.8519\n",
            "Epoch 12/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4750 - acc: 0.7963 - val_loss: 0.4329 - val_acc: 0.8889\n",
            "Epoch 13/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4573 - acc: 0.8519 - val_loss: 0.4245 - val_acc: 0.8148\n",
            "Epoch 14/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4343 - acc: 0.8519 - val_loss: 0.4048 - val_acc: 0.9630\n",
            "Epoch 15/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4243 - acc: 0.9167 - val_loss: 0.3955 - val_acc: 0.9630\n",
            "Epoch 16/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.4070 - acc: 0.8889 - val_loss: 0.3832 - val_acc: 0.9630\n",
            "Epoch 17/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3962 - acc: 0.8981 - val_loss: 0.3788 - val_acc: 0.9259\n",
            "Epoch 18/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3860 - acc: 0.9259 - val_loss: 0.3671 - val_acc: 0.9259\n",
            "Epoch 19/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3674 - acc: 0.9444 - val_loss: 0.3619 - val_acc: 0.8519\n",
            "Epoch 20/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3588 - acc: 0.9630 - val_loss: 0.3478 - val_acc: 0.9630\n",
            "Epoch 21/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3451 - acc: 0.9630 - val_loss: 0.3428 - val_acc: 0.9259\n",
            "Epoch 22/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3373 - acc: 0.9537 - val_loss: 0.3359 - val_acc: 0.9259\n",
            "Epoch 23/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.3274 - acc: 0.9444 - val_loss: 0.3248 - val_acc: 0.9630\n",
            "Epoch 24/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3203 - acc: 0.9630 - val_loss: 0.3190 - val_acc: 0.9630\n",
            "Epoch 25/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3080 - acc: 0.9537 - val_loss: 0.3170 - val_acc: 0.9259\n",
            "Epoch 26/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2992 - acc: 0.9630 - val_loss: 0.3089 - val_acc: 0.9259\n",
            "Epoch 27/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2893 - acc: 0.9722 - val_loss: 0.3015 - val_acc: 0.9259\n",
            "Epoch 28/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2798 - acc: 0.9630 - val_loss: 0.2966 - val_acc: 0.9259\n",
            "Epoch 29/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2719 - acc: 0.9722 - val_loss: 0.2902 - val_acc: 0.9259\n",
            "Epoch 30/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2658 - acc: 0.9537 - val_loss: 0.2813 - val_acc: 0.9630\n",
            "Epoch 31/64\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.2678 - acc: 0.9537 - val_loss: 0.2770 - val_acc: 0.9259\n",
            "Epoch 32/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2503 - acc: 0.9722 - val_loss: 0.2719 - val_acc: 0.9259\n",
            "Epoch 33/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2482 - acc: 0.9722 - val_loss: 0.2661 - val_acc: 0.9259\n",
            "Epoch 34/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2420 - acc: 0.9630 - val_loss: 0.2612 - val_acc: 0.9630\n",
            "Epoch 35/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2287 - acc: 0.9722 - val_loss: 0.2568 - val_acc: 0.9630\n",
            "Epoch 36/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2272 - acc: 0.9722 - val_loss: 0.2523 - val_acc: 0.9259\n",
            "Epoch 37/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2194 - acc: 0.9722 - val_loss: 0.2493 - val_acc: 0.9259\n",
            "Epoch 38/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2132 - acc: 0.9815 - val_loss: 0.2441 - val_acc: 0.9630\n",
            "Epoch 39/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.2130 - acc: 0.9722 - val_loss: 0.2472 - val_acc: 0.9259\n",
            "Epoch 40/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.2023 - acc: 0.9722 - val_loss: 0.2390 - val_acc: 0.9259\n",
            "Epoch 41/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1985 - acc: 0.9722 - val_loss: 0.2344 - val_acc: 0.9259\n",
            "Epoch 42/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1967 - acc: 0.9722 - val_loss: 0.2336 - val_acc: 0.9259\n",
            "Epoch 43/64\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1869 - acc: 0.9722 - val_loss: 0.2281 - val_acc: 0.9259\n",
            "Epoch 44/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1825 - acc: 0.9815 - val_loss: 0.2238 - val_acc: 0.9630\n",
            "Epoch 45/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1773 - acc: 0.9722 - val_loss: 0.2207 - val_acc: 0.9630\n",
            "Epoch 46/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1758 - acc: 0.9815 - val_loss: 0.2262 - val_acc: 0.8889\n",
            "Epoch 47/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1715 - acc: 0.9630 - val_loss: 0.2167 - val_acc: 0.9259\n",
            "Epoch 48/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1694 - acc: 0.9722 - val_loss: 0.2240 - val_acc: 0.8889\n",
            "Epoch 49/64\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.1693 - acc: 0.9815 - val_loss: 0.2106 - val_acc: 0.9630\n",
            "Epoch 50/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1598 - acc: 0.9815 - val_loss: 0.2083 - val_acc: 0.9630\n",
            "Epoch 51/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1549 - acc: 0.9815 - val_loss: 0.2087 - val_acc: 0.9259\n",
            "Epoch 52/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1500 - acc: 0.9815 - val_loss: 0.2048 - val_acc: 0.9259\n",
            "Epoch 53/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1477 - acc: 0.9907 - val_loss: 0.2023 - val_acc: 0.9259\n",
            "Epoch 54/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1488 - acc: 0.9815 - val_loss: 0.2026 - val_acc: 0.9259\n",
            "Epoch 55/64\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1392 - acc: 0.9907 - val_loss: 0.1986 - val_acc: 0.9259\n",
            "Epoch 56/64\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1419 - acc: 0.9815 - val_loss: 0.1973 - val_acc: 0.9259\n",
            "Epoch 57/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1359 - acc: 0.9815 - val_loss: 0.1971 - val_acc: 0.9259\n",
            "Epoch 58/64\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.1385 - acc: 0.9722 - val_loss: 0.1938 - val_acc: 0.9259\n",
            "Epoch 59/64\n",
            "22/22 [==============================] - 0s 5ms/step - loss: 0.1299 - acc: 0.9815 - val_loss: 0.1926 - val_acc: 0.9259\n",
            "Epoch 60/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1275 - acc: 0.9815 - val_loss: 0.1905 - val_acc: 0.9259\n",
            "Epoch 61/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1243 - acc: 0.9907 - val_loss: 0.1892 - val_acc: 0.9259\n",
            "Epoch 62/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1210 - acc: 0.9815 - val_loss: 0.1874 - val_acc: 0.9630\n",
            "Epoch 63/64\n",
            "22/22 [==============================] - 0s 3ms/step - loss: 0.1199 - acc: 0.9815 - val_loss: 0.1890 - val_acc: 0.9259\n",
            "Epoch 64/64\n",
            "22/22 [==============================] - 0s 4ms/step - loss: 0.1248 - acc: 0.9815 - val_loss: 0.1869 - val_acc: 0.9259\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 4)                 0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                320       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 515\n",
            "Trainable params: 515\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=.10)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=.2)\n",
        "print('X_train', X_train.shape)\n",
        "print('X_val', X_val.shape)\n",
        "print('X_test', X_test.shape)\n",
        "Y_train = to_categorical(Y_train,3)\n",
        "Y_val = to_categorical(Y_val,3)\n",
        "Y_test = to_categorical(Y_test,3)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.fit(X_train,Y_train,epochs=64,batch_size=5,validation_data=(X_val,Y_val))\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, Y_test)\n",
        "print('Akurasi Testing MLP:', accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaaLyrej-Z7y",
        "outputId": "a8740e6d-2fa9-4896-805b-ec0246f21ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0949 - acc: 1.0000\n",
            "Akurasi Testing MLP: 1.0\n"
          ]
        }
      ]
    }
  ]
}